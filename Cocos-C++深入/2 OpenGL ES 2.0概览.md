---
title: OpenGL ES2.0概览
categories: Cococs2d与OpenGL ES
---

游戏引擎对开发者提供了一级UI元素，以及组织这些UI元素构成游戏场景的接口。在游戏引擎内部，则将这些UI元素转化为一系列OpenGL ES命令的调用，并在每一帧将它们绘制到设备屏幕上。因此，了解OpenGL ES，我们能清楚的知道每个UI元素是怎样被绘制的，知道怎样使用它们会三室两厅最高的性能，同时也能更灵活的使用着色器来增强游戏画面的表现力。

### 1 GPU

GPU是集成了坐标变换、光照、图元裁剪、渲染的单一处理芯片。

衡量GPU的性能高低量每秒像素填充率，指GPU每秒所渲染的像素数量，例如，苹果A7处理器集成的GPU为Power G6430，它的像素填充率为20.8GP/s。

应用程序通常通过一些图形库来使用GPU处理图形计算，如OpenGL、Direct X等。

##### 1.1 GPU和CPU的区别

* CPU量专门为顺序串行处理而优化的几个核心组成，
* GPU则由以千计的更小、更高效的核心组成，这些核心专门为并行处理多任务而设计

### 2 什么是OpenGL ES

OpenGL ES是一套图形硬件的软件接口，它直接和GPU进行交互，使我们可以创建实时的3D图形程序。
OpenGL ES主要有1.0、2.0、3.0三个版本，大多数移动平台主要使用2.0进行绘制，OpenGL ES2.0版本针对可编程管线成硬件。

OpenGL的全部功能主要集中在怎样将程序中定义的各种2D、3D模型绘制到帧缓存中，或者如何将数据从帧缓存中读取到程序中，如保存一张场景截图。除此之外，OpenGL并不提供其他与硬件相关的功能。

### 3 OpenGL ES 2.0 渲染管线

OpenGL ES将3D场景绘制到2D屏幕上，这一过程通过一系列的渲染管线完成。OpenGL ES API就是用来向各个阶段提供一些数据各状态指令以使渲染管线能够按照要求正确的将物体绘制在屏幕上。

OpenGL ES的渲染管线如下图所示：

![](http://7xqzxs.com1.z0.glb.clouddn.com/OpenGL%20ES%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF.png)

上图中，左边的客户端骑通过调用OpenGL ES接口，将顶点、着色器程序、纹理、其他GL状态参数传入右边的GL服务端，然后在客户端调用绘制命令（如DrawArray），GL会对输入的图元逐一执行渲染管线的每个阶段，然后将每个像素的颜色值写入帧缓冲，最后视窗系统就可以将帧缓冲的颜色值显示在屏幕上了。此外，应用程序也可以从帧缓冲中将数据提取到客户端。

整个管线中，顶点着色器(Vertex Shader)、片段着色器(Fragment Shader)是可编程部分，应用程序可以通过着色器程序达到在GUP中被作用于渲染管线的目的，而在其他阶段则只能使用一些固定的GL命令影响该阶段的执行，下面逐一介绍每个阶段的作用。

##### 3.1 顶点数组

（1）概念

顶点数组：顶点数组实际上是多个数组，顶点坐标、纹理坐标、法线向量、顶点颜色，顶点的每一个颜色都可以指定一个数组，然后用统一的序号来进行访问。比如序号index3就表示取得颜色数组的第3个元素作为颜色、取得纹理坐标数组的第3个元素作为纹理坐标，取得法线向量数组的第3个元素作为法线向量、取得顶点坐标数组的第三个元素作为顶上坐标...把所有数据综合起来最后得到一个顶点。此外，我们也可以把所有数据放在一个数组，称之为交错数组。

顶点索引：假设我们绘制一个模型，这个模型由无数三角片组成，大部分三角片都是连续拼接，每两个三角形可能有一个或者两个完全相同的顶点（位置、颜色、纹理坐标），这些顶点其实是可以共享的。OpenGL ES为我们指定了一种更加灵活的方式——顶点索引数组，即我们只需要创建好必要的顶点数据，然后用索引去对应每一个对应的顶点数据。

顶点缓冲区对象（VBO）：使用VBO可以将我们的顶点数据存放在图像的内存中，而不需要存放在CPU端的内存中，就不需要在每次绘制时发送大量的数据到GPU端了。

索引缓冲对象（IBO）：和VBO一样，不同的是存储的是索引数组。

顶点数组对象（VAO）: VAO其实就是绑定VBO和IBO的一个包装对象，我们把有关联的VBO和IBO绑定到一个VAO上，我们每瓶只需要使用VAO就可以绘制了。

（2）关于OpenGL ES 3D模型的绘制：

* OpenGL不提供对3D模型的定义，在传入OpenGL之前，应用程序将3D模型转换为一组图元的集合。
* 图元是一个点、线段、或者三角形（OpenGL桌面版还包括四边形和多边形）
* 每个模型是独立绘制的，修改其中一个模型的设置不会影响其他模型。

如图，3D模型被转换为一组图元：

![](http://7xqzxs.com1.z0.glb.clouddn.com/3D%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%9B%BE%E5%85%83.png)


（3）顶点数组

图元由一个顶点或多个顶点组成，每个顶点定义一个点、一条边的一端或三角形的一个角。每个顶点关联一个数据，数据包括顶点坐标、颜色、法向量、纹理坐标。所有这些顶点相关信息构成顶点数组，这些数据被上传到GL服务端就可以进行绘制了。示例如下：通过顶点缓冲对象绑定顶点数组数据。

	void initVertexBufferObjects(vertext_t *vertexBuffer, GLushort *indices, GLunit numIndices, GLunit *vboIds)
	{
		glGenBuffers(2, vboIds);
		glBinBuffer(GL_ARRAY_BUFFER, vboIds[0]);
		glBufferData(GL_ARRAY_BUFFER, numberVertices *sizeof(vertex_t), vertexBuffer, GL_STATIC_DRAW)
	}

上述程序演示了如何通过缓冲对象（Vertex Buffer Objects）绑定顶点数组数据。

- glGenBuffers()方法分配了指定个数的VBO对象名称，这里分配了两个缓冲对象，一个用来存储顶点数组，另一个用来存储每个顶点的索引值。
- glBindBuffer设置当前缓冲对象。
- glBufferData则会将数据绑定到当前缓冲对象。

这样在开始绘制一个模型之前，我们就将顶点信息传入了OpenGL ES渲染管线。

OpenGL中的命令总是按照它被接受的顺序执行的，这意味着一组图元必须全部绘制完毕才会开始下一组图元，同时也意味着程序对帧缓冲的像素的读取结果一定是该命令之前所有OpenGL命令执行结果。

##### 3.2 顶点着色器

顶点着色器是一段类似C语言的程序，由程序员提供并在GPU上执行，对每个顶点执行一次运算。

上面顶点数组被传入顶点着色器，顶点着色器使用顶点数据来计算该顶点的坐标、颜色、光照。纹理。在渲染管线中每个顶点都被独立的执行。

顶点着色器的主要功能：

（1）执行顶点坐标变换，输出顶点在裁剪坐标系中坐标变量为gl_Position。应用程序中设置设置图元的坐标通常是本地坐标系，而GL不认识，所以在顶点着色器中要对本地坐标执行模型视图转换，将本地坐标系转为裁剪坐标系。

（2）向后面的片段着色器提供易变（Varying）变量。易变量会在图元装配之后被执行插值计算，如果是单一采样，其插值点为片段的中心，如果是多重采样，其插值点可能为多个采样片段中的任意一个位。易变量可以用来保存插值计算片段的颜色、纹理坐标等信息。

##### 3.3 图元装配

（1）图元装配的流程

![](http://7xqzxs.com1.z0.glb.clouddn.com/1030%E5%9B%BE%E5%85%83%E8%A3%85%E9%85%8D%E5%8F%8A%E5%9D%90%E6%A0%87%E7%B3%BB.png)

顶点着色器程序输出顶点坐标之后，各个顶点按照绘制命令(DrawArray或者DrawElements)中的图元类型参数及顶点索引数组被组装成一个一个图元。图元装配阶段会对图元按照如上图所示的描述各顺序执行图元操作。

在图元装配阶段，顶点坐标会经过多个坐标系的变换。如上图所示，顶点数组首先通过GL命令输入GL管线中，此时，顶点坐标位于应用程序的本地坐标系；经过顶点着色器计算之后，顶点坐标被转换为裁剪坐标系的坐标（这通常需要传入一个模型视图变换矩阵），裁剪坐标系被定义为一个视锥体；经过视锥体裁剪之后的顶点坐标经透视分离（Perspective Division）投影到屏幕或者视口（viewport）上，称为规则化（Normalized）的设备坐标系，这些坐标值的取值范围为[0, 1]；最后，规则化的坐标（xd, yd, zd）经过视口变换（Viewport Transformation）转换为屏幕坐标。

通过上述这些坐标转换，图元的顶点坐标最终被转换到屏幕坐标上。值得注意的是，在视口变换中，[-1, 1]的值被转换到视口上，所以，视锥体定义的远近平面的比例应该与视口保持一致，否则会导致图元变形。

（2）视锥体裁剪

视锥体是游戏场景中的一个可视空间，裁剪坐标系被定义在了一个视锥体裁剪空间里。由6个裁剪平面组成，分别是近平面、远平面、左平面、右平面、上平面和下平面，处于视锥体以外的图元将会补丢弃。如果图元与视锥体相交，则会发生裁剪，产生新的图元。

透视裁剪是一个比较影响性能的过程，因为每个图元都需要与6个平面进行相交计算并产生新的图元，但是一般在x轴、y轴方向超出屏幕（由glViewprot定义）的部分则无须产生新的图元，这些图元能在视口变换的时候被高效的丢弃。

视锥体在3D中通常表现为一个摄像机，其观察点为裁剪坐标的原点，方向为穿过远近平面的中点。在Cocos2d-x中，Director的setProjection()方法定义了视锥体。如下：

	void Director::setProjection(Projection projection)
	{
		Size size = _winSizeInpoints;
		setViewport();

		switch(projection)
		{

	        case Projection::_2D:
	        {
	            Mat4 orthoMatrix;
	            Mat4::createOrthographicOffCenter(0, size.width, 0, size.height, -1024, 1024, &orthoMatrix);
	            loadMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION, orthoMatrix);
	            loadIdentityMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_MODELVIEW);
	            break;
	        }

			case Projection::_3D:
			{
				float zeye = this->getZEye();
				Mat4 matrixPerspcetive, matrixLookup;

				loadIdentityMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION);
				Mat4::createPerspective(60, (GLfloat)size.width/size.height, 10, zeye+size.height/2, &matrixPerspective);
				multiplyMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION, matrixLookup);

				Vec3 eye(size.width/2, size.height/2, zeye), center(seize.width/2, size.height/2, 0.0f), up(0.0f, 1,0f, 0.0f);
				Mat4::createLookAt(eye, center, up, &matrixLookup);
				Mat4 proj3d = matrixPerspective * matrixLoopup;

				loadMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION, proj3d);
				loadIdentityMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_MODELVIEW);
			}
		}

		_projection = projection;
		GL::setProjectionMatrixDirty();

		_eventDispatcher->dispatchEvent(_eventProjectionChanged);
	}

在setProjection方法中，定义了一个张角为60度、视口比例为屏幕宽高比、近平面距离为10远平面距离为zeye + size.height/2的视锥体；摄像机位于屏幕向后zeye的距离。

在3D应用程序中可以通过修改摄像机的位置和方向，产生不同位置各角度的视锥体，以达到移到报仇机的效果。

##### 3.4 光栅化

通过图元装配，所有3D图元已经转换为屏幕上的2D图元。光栅化的主要作用是将2D图元转换为一系列的片段，并计算每个片段的位置。将几何数据经过一系列变换后最终转换为像素，从而呈现在显示设备上的过程，如图所示：

![](http://7xqzxs.com1.z0.glb.clouddn.com/0822%E5%85%89%E6%A0%85%E5%8C%96.jpg)

每个片段会执行一次片段着色器程序，在片段着色器中使用光栅化计算出的片段位置给每个片段着色，各个片段执行器的执行仍然量并行的。

在光栅化之前，要判断图元是面向观察者还是背向观察者，以决定是否需要丢弃图元。可以通过getForntFace来决定那个方向为正，并通过glCullFace命令来决定需要保留哪一面。这样做可以减少一些不必要的绘制，即GPU的浪费。

光栅化的过程主要是对图元中的片段进行采样，以决定哪些片段位于图元之内。在这个过程中，因为这些片段的坐标值为离散的整数，所以会导致精度损失，如上图边沿产生的锯齿。而光栅化会使用各种算法来保证每个片段位置尽可能准确。

在计算每个位置片段坐标之后，片段着色器就能使用这个坐标值对该片段进行着色了，这个片段为为最终屏幕上的一个像素点。此外，光栅化还需要计算那些在顶点着色器中定义的易变量的插值，这些值最终被用在片段着色器中，以计算片段最终的颜色值，如片段的纹理坐标、颜色等。

##### 3.5 片段着色器

可编程的片段着色器是实现一些高级特效（如纹理贴图、光照、环境光、阴影等功能）的基础，片段着色器的功能主要是计算每个片段的颜色值（或者丢弃该片段）。

在片段着色器出现之前，渲染管线都只是在和顶点、图元交互。在3D图形程序开发中，贴图是最重要的部分，程序可以通过GL命令将纹理数据上传至GL内存中，这些纹理可以被片段着色器使用。示例如下：

    GLuint textureId;
    glGenTextures(1, &textureId);
    glBindTexture(GL_TEXTURE_2D, textureId);
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 2, 2, 2, 0, GL_RGB, GL_UNSIGNED_BYTE, pixels);

与绑定顶点类似，该程序首先通过glGenTextres产生一个纹理对象名称，然后通过glBindTexture()方法绑定当前纹理，之后，glTexImage2D()将内存中的图像上传至OpenGL ES服务器。

片段着色器根据顶点着色器输入的顶点纹理坐标对纹理进行采样，以计算该片段的颜色值，这些值最后被写入帧缓冲。由于在实际贴图过程中可能被放大或者缩小，以及纹理坐标超出(0, 0)和(1, 1)之间的问题。为了处理这些问题，一般在绑定纹理坐标的时候可能通过glTexParameter()方法来设置纹理相关的一些处理模式，例如多级纹理。

另外，片段着色器也是执行光照等高级特效的地方。例如传给片段着色器一个光源位置和光源颜色，根据一定的公式计算出一个新颜色值，这样就可以实际光照特效了。

##### 3.6 片段测试

片段着色器输出的颜色值还要经过几个阶段的片段操作。这些操作可能会修改片段的颜色值或者丢弃该片段，最终的片段颜色值会被写入帧缓冲区，这些步骤包括像素所有权测试、裁剪测试、模板测试、深度测试、混合、抖动等。

![](http://7xqzxs.com1.z0.glb.clouddn.com/0823%E7%89%87%E6%AE%B5%E6%93%8D%E4%BD%9C.JPG)

- 像素所有权测试用来判断帧缓冲区中该位置的像素是否属于当前OpenGL ES。例如，在窗口系统中该位置可能会被其他应用程序窗口遮挡，此时该像素则不会显示。
- glScissor用于设定一个矩形区域，以执行裁剪测试，处于该区域之外的片段会被丢弃。
- 混合用来描述当前图像怎样与场景中当前位置的颜色值进行组合。
- 在完成片段测试之后，要么丢弃片段，要么将每个片段对应的颜色、深度、模板值写入帧缓冲区，最终呈现在设备的屏幕上。帧缓冲区中的颜色值可以被读到客户端应用程序中，这样可以实现绘制到纹理效果。

### 4 渲染管线中的并行计算

GPU是具备高度并行的处理器，OpenGL ES渲染管线中的并行性又是怎样的？

OpenGL ES总是按顺序执行命令，这意味着一个物体必须全部绘制完成才会开始绘制下一个物体，这样能保证在任何情况下，屏幕上显示的都是正确的图像。然而，在每一个管道的各个阶段，所有处理都是并行的，这样做保证了实时显示的性能。

这里的并行有两个方面：一方面是纵向并行，是指在每个阶段内部被拆分成多个子任务，这些子任务像工厂里的流水线一样并行处理；另一方面是横向并行，即多个顶点、多个图元、多个图元都是独立并行处理的，这很大提高了渲染的性能。

也正是因为每个顶点、图元及片段被并行处理，所以它们没有任何状态。例如，在顶点着色器程序中，我们不知道下一个要处理的顶点是什么，所有顶点着色器各片段着色器中的变量都必须通过程序获取，或者通过光栅化阶段的插值计算。

OpenGL ES是一个状态机，管道中的很多操作需要依赖当前特定的状态值，如是否执行深度测试，这些状态会影响管道中的所有顶点、图示、片段的执行。这样做能保证并行计算，从而实现更高的绘制。

### 5 构建高性能的渲染引擎

游戏是对渲染的实时性要求很高，为了达到更好的显示效果，每帧需要渲染的物体数量和纹理纹理精细度都很大的增加。所以即使OpenGL ES有很高的渲染性能，游戏引擎仍然需要采用一些更好和处理方式来使游戏引擎性能最大化，这是主要分析以下方面。

（1）减少渲染次数

通过前面我们知道，多个绘制之间是顺序执行的，减少命令的调用（其实现方式是将更多的顶点包装到一个顶点数组中）。实际上是在每个时刻让GPU做了更多事情（同一管道内的顶点并行执行）。同时，每个渲染命令都伴随着顶点、纹理数据从客户端复制到客户端的，减少渲染命令调用次数，就减少了这种数据的传输。Cocos2d-x在这方面的处理方式是使用自动批绘制，将相邻的针对同一绘制参数的命令合并在一起进行绘制，以及使用自动裁剪功能删除屏幕之外的元素。

（2）将渲染从主线程中分离

这样不仅能充分使用现代CPU多处理器、多线程的优势，使CPU有更多的时间处理游戏逻辑，还能避免CPU各GPU之间处理速度的差异导致对渲染性能的影响。同时，统一处理所有绘制命令还可以集中进行一些优化。例如，可以将相邻且使用同一纹理的绘制命令合并到一起，减少DrawCall的次数。遗憾的是，Cocos2d-x3.0仍然是一个单线程引擎，但是它已经将绘制逻辑从UI树中抽离，使绘制逻辑更灵活，易于扩展维护。

### 6 帧缓冲

OpenGL ES渲染管道最终目的是将每个像素点的颜色、深度、模板等数据输送到帧缓冲（FrameBuffer）区。

帧缓冲区存储着OpenGL ES绘制的每个像素点的所有最终信息，包括颜色、深度和模板值。一个帧缓冲上有三个对应的附加点，它们组成了一个逻辑缓冲区，分别用来存储所有像素的颜色、深度和模板数据。每个附加点可以绑定到一个渲染缓冲对象（Renderbuffer Objects）上，其中颜色和深度附加点还可以绑定到一个纹理上，这样就可以实现绘制到纹理，而不是显示设备了。

帧缓冲区通常由视窗系统提供，也可以通过应用程序创建。应用程序可以将不同的内容绘制到不同的帧缓冲中。在多个帧缓冲之间切换不需要切换OpenGL ES的上下文，通常可以使用此方式来高效地将内容绘制到纹理。（参考RenderTexture类）

![](http://7xqzxs.com1.z0.glb.clouddn.com/0823%E5%B8%A7%E7%BC%93%E5%86%B2.JPG)

只有将内容绘制到视窗提供的帧缓冲中，才能将内容输出到显示设备上，视图系统提供的帧缓冲的颜色缓冲区通常由两个缓冲对象组成，分别是一个前端缓冲和一个后端缓冲。OpenGL ES将所有内容首先绘制到后端缓冲区，然后在每一帧绘制完成之后一次性通过交换前后缓冲区将内容显示在屏幕上。之后，前端缓冲变为后端缓冲，后后端缓冲变为前端缓冲。之所以设计成双端缓冲，是因为直接绘制到设备屏幕，用户会看到一个完整的场景中的物体被一个一个绘制出来的过程，这种体验非常糟糕。